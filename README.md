# Prompting-Framework-Survey

Since the launch of ChatGPT, a powerful AI chatbot developed by OpenAI, large language models (LLMs) have made significant advancements in both academia and industry. 
From the emergence of fully supervised learning relying on feature engineering to "Pre-train, Fine-tune" (adapting pre-trained language models (PLMs) to downstream tasks), today's LLMs have transitioned to the age of Prompt Paradigm (reformulating the downstream tasks), which makes a proper prompt crucial. 
However, the booming LLMs, including excellent APIs like gpt-3.5, have inherent limitations: 1) training data exhibits temporal lag, and 2) lack the physical capabilities to perform external actions. 
Recently, we have observed the trend of utilizing prompt-based tools to enhance LLMs, and there exists a dearth of systematic literature and standardized terminology, due to the rapid evolution of this field. Therefore, in this paper, we propose the "Prompting Framework" (PF), i.e. the framework for managing, simplifying, and facilitating interaction with large language models, which adheres to four essential properties: modularity, abstraction, extensibility, and standardization, to describe this category of tools. 
The PF area is rapidly developing, leading to a proliferation of methods with widespread dispersion and a lack of standardized terminology, which has become challenging to track and compare the relationships between existing methods. Given the critical importance of PF in facilitating interactions between LLMs and the external, in this paper, we systematically analyze the overall landscape of the PF field and identify potential future research.
